{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "TensorFlow tutorial showed me how to load the MNIST data, which gives me 4 numpy arrays.\n",
    "\n",
    "https://www.tensorflow.org/tutorials/\n",
    "\n",
    "I am interested in the x_train and x_test data, which I can convert to images.\n",
    "\n",
    "I used shape to understand that x_train contains 60,000 28x28 matrix, and x_test contains 10,000 28x28 matrix.\n",
    "\n",
    "Each image data is already 28x28 matrix, so I just use matplotlib to plot some images.\n",
    "\n",
    "In this case, I print the first 3 examples from x_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADQBJREFUeJzt3X+oXPWZx/H3E60gtopaTYO6mi1RdpFolyirLpolKq4UtH8oFV2zbPEKVtjC/rHiPxWkoIvtbv+xkGoworUtxFgpdVuRRXdBQxKR+iP+IkQbDUnFSlMUS/TZP+5J9zbeOXMzv87cPO8XhJk5zzkzD0M+93vOnDPzjcxEUj1Lum5AUjcMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfiloo6c5ItFhJcTSmOWmbGQ9YYa+SPiioh4LSLejIjbhnkuSZMVg17bHxFHAK8DlwG7gC3AdZn5Sss2jvzSmE1i5D8feDMzd2TmH4EfA1cN8XySJmiY8J8C/GbO413Nsj8TETMRsTUitg7xWpJGbJgP/ObbtfjMbn1mrgPWgbv90jQZZuTfBZw25/GpwLvDtSNpUoYJ/xZgRUQsj4ijgK8Dj4+mLUnjNvBuf2buj4hbgV8CRwDrM/PlkXUmaawGPtU30It5zC+N3UQu8pG0eBl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1MBTdANExE5gH/AJsD8zV42iKWkU1qxZ07P28MMPt257ySWXtNZfe+21gXqaJkOFv/H3mfneCJ5H0gS52y8VNWz4E/hVRGyLiJlRNCRpMobd7b8oM9+NiJOBJyPi1cx8Zu4KzR8F/zBIU2aokT8z321u9wKbgPPnWWddZq7yw0Bpugwc/og4JiK+cOA+cDnw0qgakzRew+z2LwU2RcSB5/lRZv7XSLqSNHYDhz8zdwDnjLCXsbr44otb6yeeeGJrfdOmTaNsRxNw3nnn9axt2bJlgp1MJ0/1SUUZfqkowy8VZfilogy/VJThl4oaxbf6FoXVq1e31lesWNFa91Tf9FmypH3sWr58ec/a6aef3rptc/3KYc2RXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKKnOe/8Ybb2ytP/vssxPqRKOybNmy1vpNN93Us/bQQw+1bvvqq68O1NNi4sgvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0WVOc/f77vfWnzuu+++gbd94403RtjJ4mQipKIMv1SU4ZeKMvxSUYZfKsrwS0UZfqmovuf5I2I98FVgb2ae3Sw7AfgJcAawE7g2M383vjb7W7lyZWt96dKlE+pEk3LccccNvO2TTz45wk4Wp4WM/A8AVxy07DbgqcxcATzVPJa0iPQNf2Y+A7x/0OKrgA3N/Q3A1SPuS9KYDXrMvzQzdwM0tyePriVJkzD2a/sjYgaYGffrSDo0g478eyJiGUBzu7fXipm5LjNXZeaqAV9L0hgMGv7HgbXN/bXAz0bTjqRJ6Rv+iHgEeBY4KyJ2RcQ3gLuAyyLiDeCy5rGkRaTvMX9mXtejtGbEvQzlyiuvbK0fffTRE+pEo9Lv2ozly5cP/NzvvPPOwNseLrzCTyrK8EtFGX6pKMMvFWX4paIMv1TUYfPT3WedddZQ27/88ssj6kSjcs8997TW+50KfP3113vW9u3bN1BPhxNHfqkowy8VZfilogy/VJThl4oy/FJRhl8q6rA5zz+sLVu2dN3ConTssce21q+44uAffv5/N9xwQ+u2l19++UA9HXDnnXf2rH3wwQdDPffhwJFfKsrwS0UZfqkowy8VZfilogy/VJThl4ryPH/jhBNO6Oy1zznnnNZ6RLTWL7300p61U089tXXbo446qrV+/fXXt9aXLGkfPz766KOetc2bN7du+/HHH7fWjzyy/b/vtm3bWuvVOfJLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGRme0rRKwHvgrszcyzm2V3ADcBv21Wuz0zf9H3xSLaX2wI9957b2v95ptvbq33+37322+/fcg9LdTKlStb6/3O8+/fv79n7cMPP2zd9pVXXmmt9zsXv3Xr1tb6008/3bO2Z8+e1m137drVWj/++ONb6/2uYThcZWb7f5jGQkb+B4D5fpHhPzLz3OZf3+BLmi59w5+ZzwDvT6AXSRM0zDH/rRHx64hYHxHt+1+Sps6g4f8B8GXgXGA38N1eK0bETERsjYj2g0NJEzVQ+DNzT2Z+kpmfAj8Ezm9Zd11mrsrMVYM2KWn0Bgp/RCyb8/BrwEujaUfSpPT9Sm9EPAKsBr4YEbuAbwOrI+JcIIGdQPt5NElTp2/4M/O6eRbfP4ZehnLLLbe01t96663W+oUXXjjKdg5Jv2sIHnvssdb69u3be9aee+65gXqahJmZmdb6SSed1FrfsWPHKNspxyv8pKIMv1SU4ZeKMvxSUYZfKsrwS0WV+enuu+++u+sWdJA1a9YMtf3GjRtH1ElNjvxSUYZfKsrwS0UZfqkowy8VZfilogy/VFSZ8/w6/GzatKnrFhY1R36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qqu/3+SPiNOBB4EvAp8C6zPx+RJwA/AQ4A9gJXJuZvxtfq6omIlrrZ555Zmt9mqcnnwYLGfn3A/+amX8F/C3wzYj4a+A24KnMXAE81TyWtEj0DX9m7s7M55v7+4DtwCnAVcCGZrUNwNXjalLS6B3SMX9EnAF8BdgMLM3M3TD7BwI4edTNSRqfBf+GX0R8HtgIfCszf9/veGzOdjPAzGDtSRqXBY38EfE5ZoP/cGY+2izeExHLmvoyYO9822bmusxclZmrRtGwpNHoG/6YHeLvB7Zn5vfmlB4H1jb31wI/G317ksZlIbv9FwH/CLwYES80y24H7gJ+GhHfAN4GrhlPi6oqM1vrS5Z4mcow+oY/M/8X6HWAP9wE65I6459OqSjDLxVl+KWiDL9UlOGXijL8UlFO0a1F64ILLmitP/DAA5NpZJFy5JeKMvxSUYZfKsrwS0UZfqkowy8VZfilojzPr6m10J+K02Ac+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKM/zqzNPPPFEa/2aa5wKYpwc+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pqOg3B3pEnAY8CHwJ+BRYl5nfj4g7gJuA3zar3p6Zv+jzXO0vJmlombmgH0JYSPiXAcsy8/mI+AKwDbgauBb4Q2bes9CmDL80fgsNf98r/DJzN7C7ub8vIrYDpwzXnqSuHdIxf0ScAXwF2NwsujUifh0R6yPi+B7bzETE1ojYOlSnkkaq727/n1aM+DzwNPCdzHw0IpYC7wEJ3MnsocE/93kOd/ulMRvZMT9ARHwO+Dnwy8z83jz1M4CfZ+bZfZ7H8EtjttDw993tj9mfUL0f2D43+M0HgQd8DXjpUJuU1J2FfNr/d8D/AC8ye6oP4HbgOuBcZnf7dwI3Nx8Otj2XI780ZiPd7R8Vwy+N38h2+yUdngy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFTXqK7veAt+Y8/mKzbBpNa2/T2hfY26BG2dvpC11xot/n/8yLR2zNzFWdNdBiWnub1r7A3gbVVW/u9ktFGX6pqK7Dv67j128zrb1Na19gb4PqpLdOj/kldafrkV9SRzoJf0RcERGvRcSbEXFbFz30EhE7I+LFiHih6ynGmmnQ9kbES3OWnRART0bEG83tvNOkddTbHRHxTvPevRARV3bU22kR8d8RsT0iXo6If2mWd/retfTVyfs28d3+iDgCeB24DNgFbAGuy8xXJtpIDxGxE1iVmZ2fE46Ii4E/AA8emA0pIv4deD8z72r+cB6fmf82Jb3dwSHO3Dym3nrNLP1PdPjejXLG61HoYuQ/H3gzM3dk5h+BHwNXddDH1MvMZ4D3D1p8FbChub+B2f88E9ejt6mQmbsz8/nm/j7gwMzSnb53LX11oovwnwL8Zs7jXUzXlN8J/CoitkXETNfNzGPpgZmRmtuTO+7nYH1nbp6kg2aWnpr3bpAZr0eti/DPN5vINJ1yuCgz/wb4B+Cbze6tFuYHwJeZncZtN/DdLptpZpbeCHwrM3/fZS9zzdNXJ+9bF+HfBZw25/GpwLsd9DGvzHy3ud0LbGL2MGWa7DkwSWpzu7fjfv4kM/dk5ieZ+SnwQzp875qZpTcCD2fmo83izt+7+frq6n3rIvxbgBURsTwijgK+DjzeQR+fERHHNB/EEBHHAJczfbMPPw6sbe6vBX7WYS9/Zlpmbu41szQdv3fTNuN1Jxf5NKcy/hM4Alifmd+ZeBPziIi/ZHa0h9lvPP6oy94i4hFgNbPf+toDfBt4DPgp8BfA28A1mTnxD9569LaaQ5y5eUy99ZpZejMdvnejnPF6JP14hZ9Uk1f4SUUZfqkowy8VZfilogy/VJThl4oy/FJRhl8q6v8A0hKsZCOibAsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "start = 0\n",
    "end = 3\n",
    "for i in range(start, end):\n",
    "    plt.gray()\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want more training data to improve our models, but we often don't have a lot of data. So we want to make the best use of all the data and k-fold cross validation helps us do that.\n",
    "\n",
    "In k-fold CV, we divide the evenly distributed data set into k equal-sized partitions and we use 1 partition as the testing data, and the other k-1 partitions as the training data. We do this for k rotations where we rotate which partition of data we use as the testing data. \n",
    "\n",
    "For example, in 10-fold CV, we initially use the 1st block as testing data, and the other 9 as training data. Then, we rotate and we use the 2nd block as test data and use the other 9 blocks as training data, and so on.\n",
    "\n",
    "Each rotation of training and testing provides us a measure (such as accuracy), and we can average the k measures we got from k rotations, or we can study the distribution of the measures to gain more insights.\n",
    "\n",
    "This allows us to make full use of our data set and help us understand what models and what hyperparameters lead to what accuracies, and we can select our models and hyperparameters from the result of k-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_cross_val_score is the script of my implementation of k-fold CV\n",
    "\n",
    "model: the classifier model\n",
    "\n",
    "x: the features\n",
    "\n",
    "y: the labels\n",
    "\n",
    "k: the k in k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "def my_cross_val_score(model, x, y, k):\n",
    "    if(k <= 1):\n",
    "        print(\"k should be greater than 1\")\n",
    "        return\n",
    "    \n",
    "    # shuffle the input, since Iris data is grouped by labels, resample keeps x and y in order with one another\n",
    "    x, y = resample(x, y, replace=False)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    size = x.shape[0]\n",
    "    partition_size = size // k\n",
    "    \n",
    "    # k-fold CV\n",
    "    for i in range (0, k):\n",
    "        test_start = i * partition_size\n",
    "        test_end = (i + 1) * partition_size\n",
    "        \n",
    "        x_train = np.concatenate((x[0:test_start], x[partition_size:size]), axis=0)\n",
    "        y_train = np.concatenate((y[0:test_start], y[partition_size:size]), axis=0)\n",
    "        x_test = x[test_start:test_end]\n",
    "        y_test = y[test_start:test_end]\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        y_predicted = model.predict(x_test)\n",
    "        scores.append(np.mean(y_test == y_predicted))\n",
    "        \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll compare my_cross_val_score with cross_val_score from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When model is SVM\n",
      "sk accuracy: 0.9733 (+/- 0.0442)\n",
      "[1.         0.93333333 1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "my accuracy: 0.9800 (+/- 0.0427)\n",
      "[0.86666667 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.93333333]\n",
      "When model is random forest\n",
      "sk accuracy: 0.9533 (+/- 0.0521)\n",
      "[1.         0.93333333 1.         0.93333333 0.86666667 0.86666667\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "my accuracy: 0.9933 (+/- 0.0200)\n",
      "[0.93333333 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris_data = np.loadtxt('iris.data',delimiter=',')\n",
    "x = iris_data[:,0:4]\n",
    "y = iris_data[:,4]\n",
    "\n",
    "# comparison when SVM is model, cv is 10 for both\n",
    "print(\"When model is SVM\")\n",
    "\n",
    "sk_scores = model_selection.cross_val_score(svm.SVC(kernel='linear'), x, y, cv=10)\n",
    "print(\"sk accuracy: %0.4f (+/- %0.4f)\" % (sk_scores.mean(), sk_scores.std()))\n",
    "print(sk_scores)\n",
    "\n",
    "my_scores = my_cross_val_score(svm.SVC(kernel='linear'), x, y, 10)\n",
    "print(\"my accuracy: %0.4f (+/- %0.4f)\" % (my_scores.mean(), my_scores.std()))\n",
    "print(my_scores)\n",
    "\n",
    "# comparison when RF is model, cv is 10 for both\n",
    "print(\"When model is random forest\")\n",
    "\n",
    "sk_scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=10), x, y, cv=10)\n",
    "print(\"sk accuracy: %0.4f (+/- %0.4f)\" % (sk_scores.mean(), sk_scores.std()))\n",
    "print(sk_scores)\n",
    "\n",
    "my_scores = my_cross_val_score(RandomForestClassifier(n_estimators=10), x, y, 10)\n",
    "print(\"my accuracy: %0.4f (+/- %0.4f)\" % (my_scores.mean(), my_scores.std()))\n",
    "print(my_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above result, I can see that accuracies generated by my function and sklearn's function aren't very different. \n",
    "\n",
    "They shouldn't be because the algorithms for k-fold cross validation should be similar. \n",
    "\n",
    "The difference in my accuracies and sklearn accuracies is probably of because the way I shuffled the dataset and splitted the dataset to k partitions is different from the way sklearn implemented it. \n",
    "\n",
    "Because the shuffling and partitions are different, the resulting accuracies are slightly different as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9733 (+/- 0.0442)\n",
      "[1.         0.93333333 1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "RF accuracy: 0.9600 (+/- 0.0442)\n",
      "[1.         0.93333333 1.         0.93333333 0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "SVM_scores = model_selection.cross_val_score(svm.SVC(kernel='linear'), x, y, cv=10)\n",
    "print(\"SVM accuracy: %0.4f (+/- %0.4f)\" % (SVM_scores.mean(), SVM_scores.std()))\n",
    "print(SVM_scores)\n",
    "\n",
    "RF_scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=10), x, y, cv=10)\n",
    "print(\"RF accuracy: %0.4f (+/- %0.4f)\" % (RF_scores.mean(), RF_scores.std()))\n",
    "print(RF_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it seems that SVM provides more accuracy for this particular dataset if we use sklearn's cross validation accuracy score as our evaluation criteria. \n",
    "\n",
    "However, if I look at individual folds, I can see that both models achieve 100% accuracy in some folds. \n",
    "\n",
    "In addition, there are many measures for evaluating models other than just accuracy, such as recall or fall-out, and different users will use different measures to evaluate models and tune hyperparameters. \n",
    "\n",
    "Therefore, I can say that it is not sufficient to say that SVM is a better model than RF simply using cross validation scores. \n",
    "\n",
    "Furthermore, if I look at results from 2b), my function says RF has more accuracies than SVM. \n",
    "\n",
    "Therefore, I would say that whether SVM or RF is more suitable for a problem depends on the exact situation. \n",
    "\n",
    "And in this Iris data's case, I think SVM and RF are fairly equal if we are looking for high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My methodology is to:\n",
    "\n",
    "1. Load the wine train data, get x and y\n",
    "2. Use 10-fold cross validation of sklearn on the wine_train data with SVM, MLP, RF models with different hyperparameters\n",
    "3. Choose the model and hyper parameter with best accuracy because I want high accuracy when classifying wine_test data\n",
    "4. Use the model and hyper parameters from step 3 to classify wine_test data\n",
    "\n",
    "I don't shuffle the data myself because sklearn's cross_val_score shuffles them somehow.\n",
    "\n",
    "The reason I use 10 fold is because wine_train has 120 data points, so 10 fold feels about right to me for making good use of the wine_train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on linear SVC: 0.9250 (+/- 0.0786)\n",
      "Accuracy on poly SVC: 0.9500 (+/- 0.0764)\n",
      "Accuracy on MLP: 0.3417 (+/- 0.0870)\n",
      "Accuracy on RF-5: 0.9417 (+/- 0.0990)\n",
      "Accuracy on RF-7: 0.9500 (+/- 0.0408)\n",
      "Accuracy on RF-10: 0.9250 (+/- 0.0870)\n",
      "Accuracy on RF-20: 0.9667 (+/- 0.0553)\n",
      "Accuracy on RF-40: 0.9583 (+/- 0.0854)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine_train = np.loadtxt('wine.train',delimiter=',')\n",
    "\n",
    "x_train = wine_train[:,1:13]\n",
    "y_train = np.int32(wine_train[:,0])\n",
    "\n",
    "CV=10\n",
    "\n",
    "scores = model_selection.cross_val_score(svm.SVC(kernel='linear'), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on linear SVC: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(svm.SVC(kernel='poly'), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on poly SVC: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(MLPClassifier(hidden_layer_sizes=(20, 30, 20)), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on MLP: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=5), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on RF-5: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=7), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on RF-7: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=10), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on RF-10: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "                                         \n",
    "scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=20), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on RF-20: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = model_selection.cross_val_score(RandomForestClassifier(n_estimators=40), x_train, y_train, cv=CV)\n",
    "print(\"Accuracy on RF-40: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest seems to be accurate for classifying this wine data, but actually each time I re-run the code above, the RF models give different accuracies, but generally speaking, RF models are pretty accurate for my purposes. So I will use RF-20 as my final model. Now, I will train the RF-20 model with all the wine_train data and classify wine_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "x_train = wine_train[:,1:13]\n",
    "y_train = np.int32(wine_train[:,0])\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "wine_test = np.loadtxt('wine.test',delimiter=',')\n",
    "\n",
    "x_test = wine_test[:,1:13]\n",
    "\n",
    "y_predicted = model.predict(x_test)\n",
    "\n",
    "np.savetxt(\"wine_test_labels.csv\", y_predicted.astype(int), fmt='%i', delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
